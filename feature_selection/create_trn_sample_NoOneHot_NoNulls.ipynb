{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_types_file = r'../utilfiles/codes_after_reduction.csv'\n",
    "trn_rd_path = r'../utilfiles/trn_sample_NoOneHot.csv'\n",
    "validation_path = r'../utilfiles/vld_without_onehot.csv'\n",
    "sample_val_path = r'../utilfiles/val_sample_without_onehot.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_types_df = pd.read_csv(field_types_file)\n",
    "\n",
    "# Create a dictionary with field names as keys and field types as values\n",
    "field_types = dict(zip(field_types_df['codes'], field_types_df['dataType']))\n",
    "\n",
    "# Separate fields based on their types\n",
    "categorical_single_fields = [field for field, dtype in field_types.items() if dtype == 'Categorical (single)']\n",
    "categorical_multiple_fields = [field for field, dtype in field_types.items() if dtype == 'Categorical (multiple)']\n",
    "numerical_fields = [field for field, dtype in field_types.items() if dtype == 'Integer']\n",
    "continuous_fields = [field for field, dtype in field_types.items() if dtype == 'Continuous']\n",
    "\n",
    "categorical_original_fields = categorical_single_fields + categorical_multiple_fields\n",
    "numeric_original_fields = numerical_fields + continuous_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_csv(trn_rd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy='constant', fill_value=-3)\n",
    "num_imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_no_nulls_X = pd.DataFrame(cat_imputer.fit_transform(trn_df[categorical_original_fields]),\n",
    "                              columns=trn_df[categorical_original_fields].columns).astype(int)\n",
    "num_no_nulls_X = pd.DataFrame(num_imputer.fit_transform(trn_df[numeric_original_fields]),\n",
    "                               columns=trn_df[numeric_original_fields].columns).astype(int)\n",
    "\n",
    "trn_df_imputed = pd.concat([num_no_nulls_X, cat_no_nulls_X, trn_df['target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LabelEncoder handle encoding values.\n",
    "labelEncoders = {}\n",
    "for col in categorical_original_fields:\n",
    "    le = LabelEncoder()\n",
    "    trn_df_imputed[col] = le.fit_transform(trn_df_imputed[col])\n",
    "    labelEncoders[col] = le\n",
    "\n",
    "trn_df_final = trn_df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df_final.to_csv('../utilfiles/trn_sample_NoOneHot_noNulls.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_val = True # Choose if you want sample Validation or the whole validation (10% of the entire dataset)\n",
    "\n",
    "if not sample_val:\n",
    "    val_df = pd.read_csv(validation_path)\n",
    "else:\n",
    "    val_df = pd.read_csv(sample_val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_no_nulls_df_val = pd.DataFrame(cat_imputer.transform(val_df[categorical_original_fields]),\n",
    "                              columns=val_df[categorical_original_fields].columns).astype(int)\n",
    "num_no_nulls_df_val = pd.DataFrame(num_imputer.transform(val_df[numeric_original_fields]),\n",
    "                               columns=val_df[numeric_original_fields].columns).astype(int)\n",
    "\n",
    "val_df_imputed = pd.concat([num_no_nulls_df_val, cat_no_nulls_df_val, val_df['target']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_original_fields:\n",
    "    val_df_imputed[col] = labelEncoders[col].transform(val_df_imputed[col])\n",
    "\n",
    "val_df_final = val_df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_final.to_csv('../utilfiles/val_sample_NoOneHot_noNulls.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../utilfiles/numImputer.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(le, r'../utilfiles/LabelEncoders.pkl')\n",
    "joblib.dump(cat_imputer, r'../utilfiles/catImputer.pkl')\n",
    "joblib.dump(num_imputer, r'../utilfiles/numImputer.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
